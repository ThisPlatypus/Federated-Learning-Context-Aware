{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e60435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_binary(df, rul_threshold=30):\n",
    "    # Assuming \"unit\" and \"cycle\" columns exist\n",
    "    grouped = df.groupby('unit')\n",
    "    binary_labels = []\n",
    "\n",
    "    for unit, group in grouped:\n",
    "        max_cycle = group['cycle'].max()\n",
    "        for cycle in group['cycle']:\n",
    "            rul = max_cycle - cycle\n",
    "            binary_labels.append(1 if rul < rul_threshold else 0)\n",
    "\n",
    "    return binary_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d2df91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "class CMAPSSBinaryDataset(Dataset):\n",
    "    def __init__(self, df, sensor_id, rul_threshold=30, window=30):\n",
    "        self.sensor = f's{sensor_id}'\n",
    "        self.window = window\n",
    "\n",
    "        self.data = df[['unit', 'cycle', self.sensor]].copy()\n",
    "        self.labels = label_binary(df, rul_threshold)\n",
    "\n",
    "        self.X, self.y = self.create_sequences()\n",
    "\n",
    "    def create_sequences(self):\n",
    "        X, y = [], []\n",
    "        for unit in self.data['unit'].unique():\n",
    "            unit_data = self.data[self.data['unit'] == unit][self.sensor].values\n",
    "            unit_labels = self.labels[:len(unit_data)]\n",
    "            for i in range(len(unit_data) - self.window):\n",
    "                X.append(unit_data[i:i+self.window].reshape(-1, 1))\n",
    "                y.append(unit_labels[i + self.window])\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc6ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      " Data Set: FD001 \n",
      "-----------------\n",
      "Train trjectories: 100\n",
      "Test trajectories: 100\n",
      "Conditions: ONE (Sea Level)\n",
      "Fault Modes: ONE (HPC Degradation)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets.cmapss import load_data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "client_id = 5  # 0–25\n",
    "sensor_id = client_id + 1\n",
    "\n",
    "raw = load_data(\"FD001\")[0]  # Get the training dataframe\n",
    "# Rename columns to match expected names in CMAPSSBinaryDataset\n",
    "raw_renamed = raw.rename(columns={\n",
    "\t'unit_number': 'unit',\n",
    "\t'time': 'cycle',\n",
    "\tf'sensor{sensor_id}': f's{sensor_id}'\n",
    "})\n",
    "ds = CMAPSSBinaryDataset(raw_renamed, sensor_id=sensor_id)\n",
    "loader = DataLoader(ds, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e54d799f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit  cycle     s6\n",
       "0     1      1  21.61\n",
       "1     1      2  21.61\n",
       "2     1      3  21.61\n",
       "3     1      4  21.61\n",
       "4     1      5  21.61"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520d7812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit  cycle      s21\n",
       "0     1      1  23.4190\n",
       "1     1      2  23.4236\n",
       "2     1      3  23.3442\n",
       "3     1      4  23.3739\n",
       "4     1      5  23.4044"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2acfdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669da31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[32m          \u001b[0m| 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 1], expected input[32, 30, 1] to have 1 channels, but got 30 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN_LSTM_Skip1D(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 61\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, epochs, lr, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 61\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[1;32m     63\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/NEW/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NEW/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m, in \u001b[0;36mCNN_LSTM_Skip1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Apply 1D CNN: (B, seq_len, in) -> (B, in, seq_len)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#x = x.permute(0, 2, 1)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Back to (B, seq_len, cnn_filters)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NEW/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NEW/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/NEW/lib/python3.10/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NEW/lib/python3.10/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 1], expected input[32, 30, 1] to have 1 channels, but got 30 channels instead"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CNN_LSTM_Skip1D(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_filters=64, lstm_hidden=128, skip_steps=2, fc_out_dim=1):\n",
    "        super(CNN_LSTM_Skip1D, self).__init__()\n",
    "        self.skip_steps = skip_steps\n",
    "        self.lstm_hidden = lstm_hidden\n",
    "\n",
    "        # 1D Convolutional Layer\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_dim, out_channels=cnn_filters, kernel_size=1, padding='same')\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Pooling (no actual effect here, but included per spec)\n",
    "        self.pool = nn.AvgPool1d(kernel_size=1, padding=0)  # effectively a no-op\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=cnn_filters, hidden_size=lstm_hidden, batch_first=True)\n",
    "\n",
    "        # Skip connection layers (for FC transformation)\n",
    "        self.fc_v = nn.Linear(lstm_hidden, fc_out_dim)\n",
    "        self.fc_s = nn.ModuleList([nn.Linear(lstm_hidden, fc_out_dim) for _ in range(skip_steps)])\n",
    "        self.b_out = nn.Parameter(torch.zeros(fc_out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Apply 1D CNN: (B, seq_len, in) -> (B, in, seq_len)\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv1d(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)  # Back to (B, seq_len, cnn_filters)\n",
    "\n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x)  # (B, seq_len, lstm_hidden)\n",
    "        skip_outputs = []\n",
    "\n",
    "        for t in range(x.size(1)):\n",
    "            current = lstm_out[:, t]  # shape (B, hidden)\n",
    "\n",
    "            # Gather skip connections\n",
    "            skip_sum = 0\n",
    "            for i in range(self.skip_steps):\n",
    "                if t - i - 1 >= 0:\n",
    "                    skip_sum += self.fc_s[i](lstm_out[:, t - i - 1])\n",
    "\n",
    "            # Final output at timestep t\n",
    "            pV_t = self.fc_v(current)\n",
    "            pD_t = pV_t + skip_sum + self.b_out\n",
    "            skip_outputs.append(pD_t.unsqueeze(1))\n",
    "\n",
    "        return torch.cat(skip_outputs, dim=1)  # (B, seq_len, fc_out_dim)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, loader, epochs=5, lr=1e-3, device='cuda'):\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), colour='green'):\n",
    "        total_loss = 0\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "        avg_loss = total_loss / len(loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "model = CNN_LSTM_Skip1D(input_dim=1)\n",
    "model.to('cuda')\n",
    "train(model,loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum k such that P(|X - μ| < kσ) ≥ 30.0% is k = 1.1952\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def get_k_from_probability(probability_percent):\n",
    "    p = probability_percent / 100.0\n",
    "    \n",
    "    if p <= 0 or p >= 1:\n",
    "        raise ValueError(\"Probability must be between 0 and 100 (exclusive).\")\n",
    "    \n",
    "    k = math.sqrt(1 / (1 - p))\n",
    "    return round(k, 4)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        p_input = float(input(\"Enter the probability within kσ (in %, e.g., 75): \"))\n",
    "        k_result = get_k_from_probability(p_input)\n",
    "        print(f\"Minimum k such that P(|X - μ| < kσ) ≥ {p_input}% is k = {k_result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893f9fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With k = 1.19:\n",
      "At least 29.38% of the data lies within the interval:\n",
      "(16.43, 23.57)\n"
     ]
    }
   ],
   "source": [
    "def chebyshev_interval(mean, std_dev, k):\n",
    "    if std_dev < 0 or k <= 0:\n",
    "        raise ValueError(\"Standard deviation must be non-negative and k must be positive.\")\n",
    "\n",
    "    min_bound = mean - k * std_dev\n",
    "    max_bound = mean + k * std_dev\n",
    "    probability = 1 - (1 / (k ** 2))\n",
    "\n",
    "    return {\n",
    "        \"k\": round(k, 4),\n",
    "        \"probability_%\": round(probability * 100, 2),\n",
    "        \"interval\": (round(min_bound, 4), round(max_bound, 4))\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        mu = float(input(\"Enter the mean (μ): \"))\n",
    "        sigma = float(input(\"Enter the standard deviation (σ): \"))\n",
    "        k = float(input(\"Enter the value of k: \"))\n",
    "        result = chebyshev_interval(mu, sigma, k)\n",
    "        \n",
    "        print(f\"\\nWith k = {result['k']}:\")\n",
    "        print(f\"At least {result['probability_%']}% of the data lies within the interval:\")\n",
    "        print(f\"{result['interval']}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbced344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_chebyshev_bounds(arr, bwt):\n",
    "    # Flatten the array to handle weights from CNN or LSTM (any shape)\n",
    "    arr_flat = arr.flatten()\n",
    "    # Standardize the flattened array\n",
    "    arr_flat = (arr_flat - np.mean(arr_flat)) / np.std(arr_flat)\n",
    "    mean = np.mean(arr_flat)\n",
    "    std = np.std(arr_flat)\n",
    "\n",
    "    if 0 <= bwt < 25:\n",
    "        k = 1.1952\n",
    "    elif 25 <= bwt < 50:\n",
    "        k = np.sqrt(2)\n",
    "    elif 50 <= bwt < 75:\n",
    "        k = 2.236\n",
    "    elif 75 <= bwt <= 100:\n",
    "        k = 10\n",
    "    else:\n",
    "        raise ValueError(\"bwt must be in the range 0 to 100\")\n",
    "\n",
    "    lower = mean - k * std\n",
    "    upper = mean + k * std\n",
    "    mask = ((arr_flat >= lower) & (arr_flat <= upper)).astype(int)\n",
    "    percent_0 = 100 * np.sum(mask == 0) / len(mask)\n",
    "    percent_1 = 100 * np.sum(mask == 1) / len(mask)\n",
    "    print(f\"% of 0 in mask: {percent_0:.2f}%\")\n",
    "    print(f\"% of 1 in mask: {percent_1:.2f}%\")\n",
    "    return lower, upper, np.unique(mask), mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c3dc7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of 0 in mask: 0.00%\n",
      "% of 1 in mask: 100.00%\n",
      "Lower bound: -10.0\n",
      "Upper bound: 10.0\n",
      "Mean: 1.3877787807814457e-17\n",
      "Standard Deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "bwt = 75\n",
    "# Mimic weights from a CNN layer (for demonstration)\n",
    "cnn_weights = np.random.randn(64, 1, 1)  # Example: 64 filters, 1 input channel, kernel size 1\n",
    "\n",
    "#print(cnn_weights)\n",
    "lower, upper, _ , mean, std = get_chebyshev_bounds(cnn_weights, bwt)\n",
    "print(f\"Lower bound: {lower}\")\n",
    "print(f\"Upper bound: {upper}\")\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Standard Deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "912bd3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_around_mean_ecdf(weights: torch.Tensor, level: float) -> torch.Tensor:\n",
    "    assert 0 <= level <= 100, \"Level must be between 0 and 100\"\n",
    "\n",
    "    # Map input level to percent of data to keep\n",
    "    if 0 <= level < 25:\n",
    "        keep_percent = 0.3\n",
    "    elif 25 <= level < 50:\n",
    "        keep_percent = 0.5\n",
    "    elif 50 <= level < 75:\n",
    "        keep_percent = 0.8\n",
    "    else:  # 75 <= level <= 100\n",
    "        keep_percent = 1.0\n",
    "\n",
    "    flat_weights = weights.flatten()\n",
    "    sorted_weights, indices = torch.sort(flat_weights)\n",
    "    n = len(flat_weights)\n",
    "    ecdf = torch.arange(1, n + 1, dtype=torch.float32) / n\n",
    "\n",
    "    # Center interval around mean\n",
    "    mean_val = flat_weights.mean()\n",
    "    mean_idx = torch.searchsorted(sorted_weights, mean_val)\n",
    "    half_window = int((keep_percent * n) // 2)\n",
    "    start = max(mean_idx - half_window, 0)\n",
    "    end = min(mean_idx + half_window, n)\n",
    "\n",
    "    mask = torch.zeros_like(flat_weights, dtype=torch.bool)\n",
    "    mask[indices[start:end]] = 1\n",
    "    mask = mask.reshape(weights.shape).int()\n",
    "\n",
    "    percent_ones = 100 * mask.sum().item() / mask.numel()\n",
    "    percent_zeros = 100 - percent_ones\n",
    "    print(f\"% of 0 in mask (outside bounds): {percent_zeros:.2f}%\")\n",
    "    print(f\"% of 1 in mask (inside bounds): {percent_ones:.2f}%\")\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd2c40a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of 0 in mask (outside bounds): 21.88%\n",
      "% of 1 in mask (inside bounds): 78.12%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwt = 50\n",
    "# Mimic weights from a CNN layer (for demonstration)\n",
    "cnn_weights = np.random.randn(64, 1, 1)  # Example: 64 filters, 1 input channel, kernel size 1\n",
    "\n",
    "get_mask_around_mean_ecdf(torch.tensor(cnn_weights, dtype=torch.float32), level=bwt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e67f07ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79 72 66 30]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_weighted_distribution(size=100):\n",
    "    numbers = np.arange(1, 101)\n",
    "    \n",
    "    # Define weights based on the intervals:\n",
    "    # 30% for 75-100, 40% for 50-74, 20% for 25-49, 10% for 1-24\n",
    "    \n",
    "    weights = np.zeros_like(numbers, dtype=float)\n",
    "    \n",
    "    weights[(numbers >= 75) & (numbers <= 100)] = 0.30 / 26    # 26 numbers in 75-100\n",
    "    weights[(numbers >= 50) & (numbers <= 74)] = 0.40 / 25    # 25 numbers in 50-74\n",
    "    weights[(numbers >= 25) & (numbers <= 49)] = 0.20 / 25    # 25 numbers in 25-49\n",
    "    weights[(numbers >= 1) & (numbers <= 24)]  = 0.10 / 24    # 24 numbers in 1-24\n",
    "    \n",
    "    # Sample 'size' numbers with the defined weighted probabilities\n",
    "    sample = np.random.choice(numbers, size=size, p=weights)\n",
    "    return sample\n",
    "\n",
    "# Example usage\n",
    "distribution = generate_weighted_distribution(4)\n",
    "print(distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6c9653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "print(pickle.format_version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
